---
- name: install spark dependency for Debian OS family
  apt: pkg=git
  environment: spark_environment
  when: ansible_os_family == 'Debian'
  tags: ["packages","spark"]

- name: ensure spark group exist
  group: name={{spark_group}}
  tags: ["packages","spark"]

- name: ensure spark user exist
  user: name={{spark_user}} group={{spark_group}}
  tags: ["packages","spark"]

- name: ensure spark install dir exist and belong to spark user
  file: state=directory path={{spark_install_dir}} owner={{spark_user}} group={{spark_group}} recurse=yes
  tags: ["packages","spark"]

- name: retreive spark from git
  sudo_user: "{{spark_user}}"
  tags: packerio
  git: > 
     repo={{spark_repository}} dest={{spark_install_dir}} 
     version={{spark_version}} update=yes depth=1 
  environment: spark_environment
  register: spark_git_result
  tags: ["packages","spark"]

- name: spark compilation
  when: (not spark_git_result|skipped) and (spark_git_result|changed or spark_recompile is defined)
  sudo_user: "{{spark_user}}"
  shell: "{{item}}"
  args:
    chdir: "{{spark_install_dir}}"
  environment: spark_environment
  with_items:
     # - mvn dependency:resolve
     - "{{spark_compile_command}}"
  tags: ["compilation","spark"]

- name: configure spark
  template: src={{item}}.j2 dest={{spark_install_dir}}/conf/{{item}} owner={{spark_user}}
  with_items:
     - spark-defaults.conf
     - spark-env.sh
  tags: ["configuration","spark"]

- name: add symlink for hive-site.xml
  file: state=link src={{spark_hive_site_path}} dest={{spark_install_dir}}/conf/hive-site.xml force=yes
  tags: ["configuration","spark"]

- name: add symlink for hbase-site.xml
  file: state=link src={{spark_hbase_site_path}} dest={{spark_install_dir}}/conf/hbase-site.xml force=yes
  tags: ["configuration","spark"]

- name: add symlink for yarn-site.xml
  file: state=link src={{spark_yarn_site_path}} dest={{spark_install_dir}}/conf/yarn-site.xml force=yes
  tags: ["configuration","spark"]

- name: add symlink for hdfs-site.xml
  file: state=link src={{spark_hdfs_site_path}} dest={{spark_install_dir}}/conf/hdfs-site.xml force=yes
  tags: ["configuration","spark"]

- name: add symlink for core-site.xml
  file: state=link src={{spark_core_site_path}} dest={{spark_install_dir}}/conf/core-site.xml force=yes
  tags: ["configuration","spark"]

- name: add symlink for default spark version
  when: spark_set_as_default
  file: state=link src={{spark_install_dir}} dest={{spark_link_dir}}
  tags: ["configuration","spark"]

- name: configure spark env for user
  template: src=spark.sh.j2 dest=/etc/profile.d/spark.sh
  tags: ["configuration","spark"]

